import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np

# ----------------------------------------------------
# 1. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ (ìˆ˜ì •ëœ ê²½ë¡œ)
# ----------------------------------------------------
# í›ˆë ¨ ì‹œ ì‚¬ìš©í–ˆë˜ ëª¨ë¸ ì´ë¦„ (í† í¬ë‚˜ì´ì € ë¡œë“œìš©)
MODEL_NAME = "beomi/kcbert-base"
# ğŸš¨ğŸš¨ğŸš¨ ìˆ˜ì •ëœ ë¶€ë¶„: ì´ë¯¸ì§€ì—ì„œ í™•ì¸ëœ ê°€ì¥ ìµœì‹  ì²´í¬í¬ì¸íŠ¸ í´ë”ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ğŸš¨ğŸš¨ğŸš¨
FINETUNED_MODEL_PATH = "./kcbert_results/checkpoint-240"

print("âœ… í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì¤‘...")

# í›ˆë ¨ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
# TrainerëŠ” ì²´í¬í¬ì¸íŠ¸ í´ë” ì•ˆì— config.json, pytorch_model.bin ë“±ì„ ì €ì¥í•©ë‹ˆë‹¤.
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(FINETUNED_MODEL_PATH)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •

# ----------------------------------------------------
# 2. ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
# ----------------------------------------------------
def predict_sentiment(text):
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°ì„±(ê¸ì •/ë¶€ì •)ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    # í…ìŠ¤íŠ¸ í† í°í™” ë° í…ì„œ ë³€í™˜
    inputs = tokenizer(
        text,
        return_tensors='pt',
        truncation=True,
        padding=True
    )

    # ë°ì´í„°ë¥¼ ëª¨ë¸ê³¼ ë™ì¼í•œ ì¥ì¹˜(GPU ë˜ëŠ” CPU)ë¡œ ì´ë™
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        # ì˜ˆì¸¡ ìˆ˜í–‰
        outputs = model(**inputs)
        logits = outputs.logits

    # ë¡œì§“ì„ í™•ë¥ ë¡œ ë³€í™˜ (ì†Œí”„íŠ¸ë§¥ìŠ¤)
    probabilities = torch.softmax(logits, dim=1).squeeze().cpu().numpy()

    # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤(0 ë˜ëŠ” 1) ì„ íƒ
    prediction = np.argmax(probabilities)

    # ê²°ê³¼ í•´ì„
    sentiment_map = {0: "ë¶€ì • (Negative)", 1: "ê¸ì • (Positive)"}

    print("-" * 30)
    print(f"ì…ë ¥ í…ìŠ¤íŠ¸: {text}")
    print(f"ì˜ˆì¸¡ ê²°ê³¼: {sentiment_map[prediction]}")
    print(f"ê¸ì • í™•ë¥ : {probabilities[1]:.4f}")
    print(f"ë¶€ì • í™•ë¥ : {probabilities[0]:.4f}")
    print("-" * 30)

    return prediction

# ----------------------------------------------------
# 3. ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
# ----------------------------------------------------
print("ğŸš€ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¡œ ê°ì„± ì˜ˆì¸¡ ì‹œì‘...")

# ê¸ì •ì ì¸ ì˜ˆì‹œ
predict_sentiment("ëŠê¸ˆë§ˆê°€ ì¢‹ì•„í• ë“¯")

# ë¶€ì •ì ì¸ ì˜ˆì‹œ
predict_sentiment("ëŠê¸ˆë§ˆ ë§Œìˆ˜ë¬´ê°•.")

# ì¤‘ë¦½ì ì¸/ëª¨í˜¸í•œ ì˜ˆì‹œ
predict_sentiment("ê·¸ëƒ¥ í‰ë²”í–ˆê³ , íŠ¹ë³„íˆ ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„ ì•Šì•˜ìŠµë‹ˆë‹¤.")

print("\nâœ… ì˜ˆì¸¡ ì™„ë£Œ!")